# Classification du Paludisme par Deep Learning

## üìã Description du Projet

Ce projet impl√©mente un syst√®me de classification d'images pour d√©tecter automatiquement le paludisme dans des cellules sanguines (h√©maties) en utilisant des r√©seaux de neurones convolutifs (CNN). Le paludisme √©tant une maladie infectieuse grave touchant des millions de personnes chaque ann√©e, particuli√®rement dans les r√©gions tropicales et subtropicales, ce projet vise √† acc√©l√©rer et am√©liorer la pr√©cision du diagnostic.

### Objectif

D√©velopper et entra√Æner des mod√®les de Deep Learning capables de diff√©rencier les h√©maties infect√©es par le parasite du paludisme de celles qui sont saines, offrant ainsi une assistance automatis√©e aux professionnels de sant√©.

## üèóÔ∏è Architecture du Projet

```
malaria_classification/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ malaria_hematie_dataset/
‚îÇ       ‚îú‚îÄ‚îÄ Parasitee/          # Images d'h√©maties infect√©es
‚îÇ       ‚îî‚îÄ‚îÄ Non_parasitee/      # Images d'h√©maties saines
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ config.py               # Configuration globale
‚îÇ   ‚îú‚îÄ‚îÄ data_manager.py         # Classe DataManager (chargement et augmentation)
‚îÇ   ‚îú‚îÄ‚îÄ trainer.py              # Classe Trainer (entra√Ænement avec callbacks)
‚îÇ   ‚îú‚îÄ‚îÄ evaluator.py            # Classe Evaluator (√©valuation et m√©triques)
‚îÇ   ‚îî‚îÄ‚îÄ models/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ base_model.py       # Classe abstraite BaseModel
‚îÇ       ‚îú‚îÄ‚îÄ simple_cnn.py       # Classe SimpleCNN (from scratch)
‚îÇ       ‚îú‚îÄ‚îÄ vgg16_model.py      # Classe VGG16Model (fine-tuned)
‚îÇ       ‚îî‚îÄ‚îÄ resnet50_model.py   # Classe ResNet50Model (fine-tuned)
‚îú‚îÄ‚îÄ resultats/                  # R√©sultats d'entra√Ænement
‚îú‚îÄ‚îÄ main.py                     # Script principal (MalariaClassificationPipeline)
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

## üìä Structure des Donn√©es

### Organisation

Le dataset est organis√© en deux cat√©gories:
- **Parasitee**: H√©maties infect√©es par le parasite du paludisme
- **Non_parasitee**: H√©maties saines

### Pr√©paration des Donn√©es

#### 1. Chargement et Normalisation
Les images sont charg√©es depuis les dossiers, redimensionn√©es √† 64x64 pixels, et normalis√©es entre 0 et 1 en divisant par 255.

#### 2. S√©paration des Donn√©es
- **70%** pour l'entra√Ænement
- **15%** pour la validation
- **15%** pour le test

Cette s√©paration est effectu√©e de mani√®re stratifi√©e pour maintenir la proportion des classes.

#### 3. Augmentation des Donn√©es

L'augmentation de donn√©es est appliqu√©e uniquement sur l'ensemble d'entra√Ænement pour √©viter l'overfitting et am√©liorer la g√©n√©ralisation. Les transformations incluent:
- **Rotation al√©atoire**: jusqu'√† 20 degr√©s
- **D√©calage horizontal/vertical**: jusqu'√† 20% de la taille de l'image
- **Cisaillement**: jusqu'√† 20%
- **Zoom**: jusqu'√† 20%
- **Retournement horizontal et vertical**: pour simuler diff√©rentes orientations

## üß† Mod√®les Impl√©ment√©s

### 1. CNN Simple (From Scratch) - Classe `SimpleCNN`

**Classe:** `SimpleCNN` h√©rite de `BaseModel`

**Architecture:**
- **Bloc 1**: Conv2D(32 filtres, 3x3) ‚Üí MaxPooling(2x2) ‚Üí BatchNormalization
- **Bloc 2**: Conv2D(64 filtres, 3x3) ‚Üí MaxPooling(2x2) ‚Üí BatchNormalization
- **Bloc 3**: Conv2D(128 filtres, 3x3) ‚Üí MaxPooling(2x2) ‚Üí BatchNormalization
- **Classifieur**: Flatten ‚Üí Dense(256) ‚Üí Dropout(0.5) ‚Üí Dense(128) ‚Üí Dropout(0.3) ‚Üí Dense(2, softmax)

**Caract√©ristiques:**
- Mod√®le construit enti√®rement from scratch
- BatchNormalization pour stabiliser l'entra√Ænement
- Dropout pour r√©duire l'overfitting
- Activation ReLU pour introduire la non-lin√©arit√©

### 2. VGG16 Fine-tuned - Classe `VGG16Model`

**Classe:** `VGG16Model` h√©rite de `BaseModel`

**Architecture:**
- **Encodeur**: VGG16 pr√©-entra√Æn√© sur ImageNet (sans les couches de classification)
- **Gel**: Toutes les couches sauf les 4 derni√®res blocs sont gel√©es
- **Classifieur personnalis√©**: Flatten ‚Üí Dense(512) ‚Üí Dropout(0.5) ‚Üí Dense(256) ‚Üí Dropout(0.3) ‚Üí Dense(2, softmax)

**Pr√©traitement sp√©cifique:**
Les images sont pr√©trait√©es avec `preprocess_input` de VGG16 qui applique la normalisation standard utilis√©e lors de l'entra√Ænement sur ImageNet (soustraction de la moyenne des canaux RGB).

**Avantages:**
- Utilise des features pr√©-apprises sur un large dataset
- N√©cessite moins de donn√©es d'entra√Ænement
- Converge plus rapidement

### 3. ResNet50 Fine-tuned - Classe `ResNet50Model`

**Classe:** `ResNet50Model` h√©rite de `BaseModel`

**Architecture:**
- **Encodeur**: ResNet50 pr√©-entra√Æn√© sur ImageNet (sans les couches de classification)
- **Gel**: Toutes les couches sauf les 10 derni√®res sont gel√©es
- **Classifieur personnalis√©**: GlobalAveragePooling2D ‚Üí Dense(512) ‚Üí Dropout(0.5) ‚Üí Dense(256) ‚Üí Dropout(0.3) ‚Üí Dense(2, softmax)

**Pr√©traitement sp√©cifique:**
Les images sont pr√©trait√©es avec `preprocess_input` de ResNet50.

**Avantages:**
- Architecture avec connexions r√©siduelles (skip connections)
- √âvite le probl√®me de gradient vanishing
- Tr√®s performant pour la classification d'images

## üèõÔ∏è Architecture POO (Programmation Orient√©e Objet)

Le projet utilise une architecture orient√©e objet avec plusieurs classes principales:

### Classe `BaseModel` (Abstraite)
Classe de base pour tous les mod√®les CNN avec m√©thodes communes:
- `build()`: Construction du mod√®le (m√©thode abstraite)
- `compile_model()`: Compilation avec optimizer Adam
- `get_model()`: R√©cup√©ration du mod√®le Keras
- `save_weights()`, `load_weights()`: Sauvegarde/chargement des poids

### Classe `DataManager`
Gestion compl√®te des donn√©es:
- `load_images_from_folders()`: Chargement depuis dossiers
- `prepare_data()`: Split train/val/test avec stratification
- `get_data_generator()`: Cr√©ation du g√©n√©rateur d'augmentation
- `show_augmentation_examples()`: Visualisation des augmentations
- `get_dataset_info()`: Informations sur le dataset

### Classe `Trainer`
Entra√Ænement des mod√®les avec callbacks:
- `create_callbacks()`: Cr√©ation EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
- `train()`: Boucle d'entra√Ænement compl√®te
- `save_learning_curves()`: Sauvegarde des courbes

### Classe `Evaluator`
√âvaluation et visualisation:
- `evaluate()`: Calcul de toutes les m√©triques
- `print_results()`: Affichage des r√©sultats
- `plot_confusion_matrix()`: Matrice de confusion
- `plot_roc_curve()`: Courbe ROC avec AUC
- `compare_models()`: Comparaison multi-mod√®les (m√©thode statique)

### Classe `MalariaClassificationPipeline`
Orchestration compl√®te du projet:
- `load_data()`: Chargement via DataManager
- `create_models()`: Instanciation des 3 mod√®les
- `train_all_models()`: Entra√Ænement avec Trainer
- `evaluate_all_models()`: √âvaluation avec Evaluator
- `compare_models()`: Comparaison finale
- `run()`: Ex√©cution compl√®te du pipeline

## üéØ Entra√Ænement

### Hyperparam√®tres

```python
TAILLE_IMAGE = 64
TAILLE_BATCH = 32
NOMBRE_EPOCHS = 30
TAUX_APPRENTISSAGE = 0.001
PATIENCE = 5 (pour early stopping)
```

### Callbacks Utilis√©s

#### 1. Early Stopping
- **Surveillance**: Validation loss
- **Patience**: 5 epochs
- **Fonction**: Arr√™te l'entra√Ænement si la loss de validation ne s'am√©liore pas pendant 5 epochs cons√©cutifs
- **Restauration**: Restaure les poids du meilleur epoch

#### 2. ReduceLROnPlateau
- **Surveillance**: Validation loss
- **Facteur de r√©duction**: 0.5 (divise le learning rate par 2)
- **Patience**: 3 epochs
- **Learning rate minimum**: 1e-7
- **Fonction**: R√©duit le learning rate lorsque la performance stagne, permettant une optimisation plus fine

#### 3. ModelCheckpoint
- **Surveillance**: Validation accuracy
- **Sauvegarde**: Uniquement les poids du meilleur mod√®le
- **Format**: fichier `.weights.h5`

### Optimiseur

L'optimiseur **Adam** est utilis√© avec un learning rate initial de 0.001. Adam combine les avantages de:
- **AdaGrad**: Adaptation du learning rate pour chaque param√®tre
- **RMSprop**: Utilisation de moyennes mobiles des gradients

### Fonction de Perte

**Categorical Crossentropy** est utilis√©e car nous avons une classification multi-classes (2 classes: Parasit√©e et Non parasit√©e).

## üìà √âvaluation

### M√©triques Calcul√©es

#### 1. Accuracy (Exactitude)
Proportion de pr√©dictions correctes sur le total.
```
Accuracy = (TP + TN) / (TP + TN + FP + FN)
```

#### 2. Precision (Pr√©cision)
Proportion de vrais positifs parmi les pr√©dictions positives.
```
Precision = TP / (TP + FP)
```
Utile quand le co√ªt d'un faux positif est √©lev√©.

#### 3. Recall (Rappel / Sensibilit√©)
Proportion de vrais positifs parmi tous les cas r√©ellement positifs.
```
Recall = TP / (TP + FN)
```
Utile quand le co√ªt d'un faux n√©gatif est √©lev√© (crucial en m√©decine).

#### 4. F1-Score
Moyenne harmonique de la pr√©cision et du rappel.
```
F1 = 2 * (Precision * Recall) / (Precision + Recall)
```
√âquilibre entre pr√©cision et rappel.

#### 5. Sensibilit√©
Identique au Recall. Mesure la capacit√© √† d√©tecter les cas positifs (h√©maties infect√©es).

#### 6. Sp√©cificit√©
Proportion de vrais n√©gatifs parmi tous les cas r√©ellement n√©gatifs.
```
Sp√©cificit√© = TN / (TN + FP)
```
Mesure la capacit√© √† identifier correctement les cas n√©gatifs (h√©maties saines).

### Visualisations G√©n√©r√©es

#### 1. Courbes d'Apprentissage
Pour chaque mod√®le, ces graphiques montrent:
- **Loss**: √âvolution de la perte sur train et validation
- **Accuracy**: √âvolution de l'exactitude sur train et validation

Permettent de d√©tecter l'overfitting (√©cart croissant entre train et validation).

#### 2. Matrice de Confusion
Tableau crois√© montrant:
- **Vrais Positifs (TP)**: Parasit√©e pr√©dite correctement
- **Vrais N√©gatifs (TN)**: Non parasit√©e pr√©dite correctement
- **Faux Positifs (FP)**: Non parasit√©e pr√©dite comme Parasit√©e
- **Faux N√©gatifs (FN)**: Parasit√©e pr√©dite comme Non parasit√©e

#### 3. Courbe ROC et AUC
- **ROC (Receiver Operating Characteristic)**: Trace le taux de vrais positifs vs taux de faux positifs
- **AUC (Area Under Curve)**: Aire sous la courbe ROC
  - AUC = 1.0: Classifieur parfait
  - AUC = 0.5: Classifieur al√©atoire
  - AUC > 0.8: Bon classifieur

#### 4. Graphique de Comparaison
Compare les 6 m√©triques pour les 3 mod√®les sur un m√™me graphique, permettant d'identifier rapidement le meilleur mod√®le.

## üöÄ Utilisation

### Installation

```bash
# Cloner le projet
cd malaria_classification

# Cr√©er un environnement virtuel
python3 -m venv env
source env/bin/activate  # Sur Mac/Linux
# env\Scripts\activate  # Sur Windows

# Installer les d√©pendances
pip install -r requirements.txt
```

### Pr√©paration des Donn√©es

Organisez vos images dans la structure suivante:
```
data/malaria_hematie_dataset/
‚îú‚îÄ‚îÄ Parasitee/
‚îÇ   ‚îú‚îÄ‚îÄ image1.png
‚îÇ   ‚îú‚îÄ‚îÄ image2.png
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ Non_parasitee/
    ‚îú‚îÄ‚îÄ image1.png
    ‚îú‚îÄ‚îÄ image2.png
    ‚îî‚îÄ‚îÄ ...
```

### Ex√©cution

```bash
# Lancer l'entra√Ænement complet des 3 mod√®les
python3 main.py
```

Le script va:
1. Charger et pr√©parer les donn√©es
2. Afficher des exemples d'augmentation
3. Entra√Æner le CNN Simple
4. Entra√Æner VGG16
5. Entra√Æner ResNet50
6. √âvaluer chaque mod√®le sur le test set
7. G√©n√©rer toutes les visualisations
8. Comparer les performances

### R√©sultats

Tous les r√©sultats sont sauvegard√©s dans le dossier `resultats/`:
- `CNN_Simple.weights.h5` - Poids du mod√®le CNN simple
- `VGG16.weights.h5` - Poids du mod√®le VGG16
- `ResNet50.weights.h5` - Poids du mod√®le ResNet50
- `CNN_Simple_courbes.png` - Courbes d'apprentissage
- `VGG16_courbes.png` - Courbes d'apprentissage
- `ResNet50_courbes.png` - Courbes d'apprentissage
- `CNN_Simple_matrice_confusion.png` - Matrice de confusion
- `VGG16_matrice_confusion.png` - Matrice de confusion
- `ResNet50_matrice_confusion.png` - Matrice de confusion
- `CNN_Simple_courbe_roc.png` - Courbe ROC
- `VGG16_courbe_roc.png` - Courbe ROC
- `ResNet50_courbe_roc.png` - Courbe ROC
- `comparaison_modeles.png` - Comparaison des 3 mod√®les
- `augmentation_exemples.png` - Exemples d'augmentation de donn√©es

## üîç Interpr√©tation des R√©sultats

### Choix du Meilleur Mod√®le

Le meilleur mod√®le d√©pend du contexte d'utilisation:

**Pour un d√©pistage m√©dical:**
- Privil√©gier le **Recall/Sensibilit√©** √©lev√© (minimiser les faux n√©gatifs)
- Un faux n√©gatif (ne pas d√©tecter un malade) est plus grave qu'un faux positif
- Regarder l'AUC pour la performance globale

**Pour un syst√®me de confirmation:**
- Privil√©gier la **Pr√©cision** √©lev√©e (minimiser les faux positifs)
- √âviter d'alarmer inutilement avec des faux positifs

**Pour un √©quilibre:**
- Choisir le mod√®le avec le meilleur **F1-Score**
- Ou le meilleur **AUC**

### Lecture de la Matrice de Confusion

```
                 Pr√©diction
              Parasit√©e  Non_parasit√©e
R√©alit√©
Parasit√©e        TP          FN
Non_parasit√©e    FP          TN
```

**Cas id√©al:** Diagonale principale √©lev√©e (TP et TN), hors diagonale faible (FP et FN).

### Lecture de la Courbe ROC

- Courbe proche du coin sup√©rieur gauche = Bon mod√®le
- Courbe sur la diagonale = Mod√®le al√©atoire
- AUC √©lev√© (> 0.9) = Excellent mod√®le pour la classification

## üõ†Ô∏è Technologies Utilis√©es

- **TensorFlow/Keras**: Framework de Deep Learning
- **NumPy**: Calculs num√©riques
- **Pandas**: Manipulation de donn√©es
- **Scikit-learn**: M√©triques et preprocessing
- **Matplotlib/Seaborn**: Visualisations
- **Pillow**: Traitement d'images

## üìù M√©thodologie de D√©veloppement

### 1. Manipulation de la Donn√©e
- Chargement depuis les dossiers
- Normalisation [0, 1]
- Encodage des labels
- Augmentation de donn√©es avec ImageDataGenerator
- Visualisation des transformations

### 2. Entra√Ænement de 3 Mod√®les
- Impl√©mentation de 2 callbacks (EarlyStopping, ReduceLROnPlateau)
- CNN from scratch avec Sequential et Dropout
- Fine-tuning de VGG16 pr√©-entra√Æn√© sur ImageNet
- Fine-tuning de ResNet50 pr√©-entra√Æn√© sur ImageNet
- Sauvegarde des poids des 3 mod√®les

### 3. Test des Mod√®les
- Calcul de la matrice de confusion
- Calcul de toutes les m√©triques (accuracy, precision, recall, f1-score, sensibilit√©, sp√©cificit√©)
- Affichage des courbes ROC et calcul de l'AUC
- Interpr√©tation et comparaison des r√©sultats

## üìö R√©f√©rences

- Dataset: NIH Malaria Datasets - https://ceb.nlm.nih.gov/repositories/malaria-datasets/
- VGG16: "Very Deep Convolutional Networks for Large-Scale Image Recognition"
- ResNet50: "Deep Residual Learning for Image Recognition"
- Transfer Learning: Utilisation de mod√®les pr√©-entra√Æn√©s sur ImageNet

## üë• Auteurs

Projet r√©alis√© dans le cadre du FOAD du 05/02/2026

## üìÑ Licence

Ce projet est fourni √† des fins √©ducatives.
